% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[review]{ACL2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning}


% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}


% If the title and author information does not fit in the area allocated, uncomment the following
%
% \setlength\titlebox{5}
%
% and set <dim> to something 5cm or larger.

\title{When was I when...? Improving model's temporal reasoning through harder data}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Paulius Kutka \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\\And
  Tomas Eglinskas \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  \texttt{email@domain} \\}

\begin{document}
\maketitle
\begin{abstract}
In this paper, our goal is to improve models capability to answer time-based questions. More specifically, we focus on reducing model's bias towards preferring answers that contain time-specific words, such as year or specific dates, over non-time specific words, such as events happening at some time. By generating adversarial datasets with multiple levels of complexity, we found that we could improve model's performance on SQuAD by x percent.
\end{abstract}

\section{Introduction}

The capabilities of state-of-the-art models in reading comprehension tasks have long advanced since the early days. Nowadays, they are able to stitch pieces of information quite effectively, achieving nearly human performance. (TODO: link to the baseline comparison)

However, many modern models still struggle with temporal information which has been a subject of many recent studies (\citep{wallat2024temporalblindspotslarge}).

In this paper, we use Electra-small model \citep{clark-2020} and SQuAD dataset \citep{rajpurkar-2016}, a dataset of more than 100,000 entries with roughly 8.9\% being date based answers, to assess model's capability to work with time based questions.

We first compute the overlap score for all the predictions and pick the ones that start with \textit{When} and have an overlap score of 0. We then categorise them into specific error classes and focus on one, namely Temporal Preference Error, where model prefers time-related answers over answers that contain non-time related words. We then verify our hypothesis by creating adversarial datasets of multiple complexity levels and later attempt to use the same data to improve our model's reasoning.

\section{Approach}

\subsection{Data Sources}

We primarily focus on SQuAD dataset as our baseline. We felt like it was straightforward enough and had sufficient amounts of errors for us to have a shot at improving the model's performance on it.

To generate adversarial examples, we used our own implementation of the human-in-the-loop method \citep{Bartolo_2020}, where human looks at example generated by an LLM, verifies it and then passes to the model, to either add or not add it to the list (see Figure~\ref{figure:evaluation_process}) For question generation, we used GPT-4o model from OpenAI.

\begin{figure}[h!]
\centering
\begin{tikzpicture}[
    node distance=2.5cm and 2.5cm,
    every node/.style={align=center, font=\sffamily},
    startstop/.style={rectangle, rounded corners, draw=black, thick, text width=2cm, minimum height=1cm},
    process/.style={rectangle, draw=black, thick, text width=2.4cm, minimum height=1cm},
    decision/.style={diamond, draw=black, thick, text width=2cm, minimum height=1cm, aspect=2},
    arrow/.style={thick,->,>=stealth},
    scale=0.7, transform shape % Scale down the entire graph
]

% Nodes
\node[startstop] (start) {1. GPT-4o generates question $q$ \\ and selects answer $a_h$ \\ for passage $p$.};
\node[decision, above=of start] (human) {2. $(p, q)$ verified by human. \\};
\node[process, right=of start] (model) {3. $(p, q)$ sent to the model. \\ Model predicts answer $a_m$.};
\node[decision, below=of model] (f1) {4. F1 score between \\ $a_h$ and $a_m$ is calculated; \\ if F1 > 40\%, human loses.};
\node[process, left=of f1] (restart) {5(b). Human loses. \\ The process is restarted \\ (same $p$).};
\node[process, below=of f1] (adversarial) {6(a). Human wins. \\ The human-sourced adversarial \\ example $(p, q, a_h)$ is collected.};

% Arrows
\draw[arrow] (start) -- (human); % Arrow from start to decision
\draw[arrow] (human.east)  -- ++(3.8,0) -- node[midway, above] {Approved} (model.north); % Rectangular arrow for Approved
\draw[arrow] (human.west) -- ++(-1,0) |- node[pos=0.2, above] {Not Approved} (start.west); % Rectangular loopback for Not Approved
\draw[arrow] (model) -- (f1);
\draw[arrow] (f1) -- node[midway, above, sloped] {Yes \\ ($F1 > 40\%$)} (restart);
\draw[arrow] (f1) -- node[midway, above, sloped] {No \\ ($F1 \leq 40\%$)} (adversarial);
\draw[arrow] (restart.west) -- ++(-1,0) |- (start.west);

\end{tikzpicture}
\caption{Adversarial evaluation process: GPT-4o generates a question and selects an answer verified by human, and the model’s prediction is compared to determine whether example should be added to the dataset}
\label{figure:evaluation_process}
\end{figure}

Using this approach, we ended up generating a dataset consisting of 200 examples. We focused on changing the existing data by replacing the obvious date values by events consisting on non-time related words (see Table~\ref{tab:changed_data}). We then split the dataset into 100 for training and a 100 for testing.

\begin{table*}[h!]
\centering
\begin{tabular}{|p{2cm}|p{5cm}|p{5cm}|p{2cm}|p{2cm}|}
\hline
\textbf{Question} & \textbf{Previous Context} & \textbf{New Context} & \textbf{Previous Answer} & \textbf{New Answer} \\
\hline
When did Lev's Stadium open? & On May 21, 2013, NFL owners at their spring meetings in Boston voted and awarded the game to Levi's Stadium. The \$1.2 billion stadium opened in \textcolor{blue}{2014}. It is the first Super Bowl held in the San Francisco Bay Area since Super Bowl XIX in 1985, and the first in California since Super Bowl XXXVII took place in San Diego in 2003. & On May 21, 2013, NFL owners at their spring meetings in Boston voted and awarded the game to Levi's Stadium. The \$1.2 billion stadium opened \textcolor{red}{when Lithuania rolled out Euro}. It is the first Super Bowl held in the San Francisco Bay Area since Super Bowl XIX in 1985, and the first in California since Super Bowl XXXVII took place in San Diego in 2003. & \textcolor{blue}{2014} & \textcolor{red}{when Lithuania rolled out Euro} \\
\hline
\end{tabular}
\caption{A single example from generated adversarial dataset (Previous answer in blue, changed answer in red)}
\label{tab:changed_data}
\end{table*}

\subsection{Model}

We decided to stick with the default Electra-Small model as suggested in the final project instructions. We felt it gave the best performance to training time/resource complexity ratio, perfect for quick iterations and assessments.

\subsection{Analysis}

To analyse the prediction errors initially, we used simple filtering of \textit{When} questions by their overlap score. The overlap score was calculated on the fly, using Jackard's Index:
\[
J(A, B) = \frac{|A \cap B|}{|A \cup B|}
\]
, where A and B are actual and predicted token respectfully. We then manually labelled all the filtered errors and picked the most promising ones.

\subsection{Experiments}

TBD

\section{Results}

\subsection{Analysis}

To establish a baseline, we ran off-the-self Electra-small model on the SQuAD dataset, achieving EM of 76.23 and F1 of 84.46.

\begin{table*}[h!]
\centering
\begin{tabular}{|p{3cm}|p{7cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
\textbf{Category} & \textbf{Example Context} & \textbf{Question} & \textbf{Answer} & \textbf{Predicted Answer} \\
\hline
Granularity Error & During the Southern Song dynasty, the descendant of Confucius at Qufu, the Duke Yansheng Kong Duanyou fled south with the Song Emperor to Quzhou, while the newly established Jin dynasty (\textcolor{blue}{1115}–\textcolor{red}{1234}) in the north appointed Kong Duanyou's brother Kong Duancao who remained in Qufu as Duke Yansheng. & When did the Jin dynasty begin? & \textcolor{blue}{1115} & \textcolor{red}{1115–1234} \\
\hline
Proximity or Lexical Bias & As a result, ABC and Disney's first television collaboration ended in \textcolor{blue}{1961} (the network would resume its relationship with Disney in \textcolor{red}{1985}, when the anthology series returned to the network for a three-season run as the Disney Sunday Movie until it lost the rights to NBC again in 1988). & When did ABC and Disney's television relationship lapse? & \textcolor{blue}{1961} & \textcolor{red}{1985} \\
\hline
Temporal Preference Error & Since \textcolor{red}{2011}, Warsaw Gallery Weekend is held on the \textcolor{blue}{last weekend of September}. & When is the Warsaw Gallery Weekend held? & \textcolor{blue}{Last weekend of September} & \textcolor{red}{2011} \\
\hline
Rephrasing Misunderstanding & Montpellier was among the most important of the 66 "villes de sûreté" that the Edict of \textcolor{red}{1598} granted to the Huguenots...  Even before the Edict of Alès (\textcolor{blue}{1629}), Protestant rule was dead and the ville de sûreté was no more.  & When was this proclamation issued? & \textcolor{blue}{1629} & \textcolor{red}{1598} \\
\hline
Temporal Sequence Error & The last glacial ran from \textcolor{blue}{~74,000 (BP = Before Present)}, until the \textcolor{red}{end of the Pleistocene} (~11,600 BP). & When did the last glacial start? & \textcolor{blue}{~74,000 BP} & \textcolor{red}{End of the Pleistocene} \\
\hline
Wrong Question/Label & In \textcolor{red}{1957}, Kosanović's secretary Charlotte Muzar transported Tesla's ashes from the United States to Belgrade. The ashes are displayed in a gold-plated sphere on a marble pedestal in the \textcolor{blue}{Nikola Tesla Museum}. & When are the ashes now? & \textcolor{blue}{Nikola Tesla Museum} & \textcolor{red}{1957} \\
\hline
\end{tabular}
\caption{Concrete Examples of Errors (Correct answers in blue, predicted answers in red)}
\label{tab:error_examples}
\end{table*}

We then hand-picked the incorrectly answered examples (see Table~\ref{tab:error_examples}) and manually classified them (see Table~\ref{tab:error_categories}). We then observed that by far the most errors came from proximity and lexical bias (16 out of 51 total) with granularity errors being the second (10 out of 51 total).

\begin{table*}[h!]
\centering
\begin{tabular}{|p{3cm}|p{8cm}|p{1cm}|}
\hline
\textbf{Category} & \textbf{Explanation} & \textbf{\# Examples} \\
\hline
Granularity Error & Answer given is too broad & 10 \\
\hline
Proximity or Lexical Bias & Answers that are the closest to the subject in the question are preferred & 16 \\
\hline
Temporal Preference Error & Most common time representations (dates, months) are preferred over other types & 4 \\
\hline
Rephrasing Misunderstanding & Rephrased questions are completely misunderstood & 6 \\
\hline
Temporal Sequence Error & Event sequence is confused & 2 \\
\hline
Wrong Question/Label & Either the question or its label is wrong & 4 \\
\hline
% Non-temporal Question & Questions not relating to time & 6 \\
% Unclear & Examples where we couldn't determine the category & 3 \\
\hline
\end{tabular}
\caption{Error Categories and Explanations}
\label{tab:error_categories}
\end{table*}


\subsection{Fixing}

To address the shortcomings of the model, we fine-tune it using the subset of data we generated during analysis. As the result, the model performs better on those examples, however, it becomes less performant on the whole dataset.

\section{Conclusions}

TBD

\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}

\end{document}
