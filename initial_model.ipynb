{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkey/fp-dataset-artifacts/blob/main/initial_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Environment"
      ],
      "metadata": {
        "id": "82V6cZ2M-f0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Set environment varialbes\n",
        "TRAIN_PATH = '/content/drive/My Drive/model_training'\n",
        "os.environ['TRAIN_PATH'] = TRAIN_PATH\n",
        "\n",
        "# Import secrets\n",
        "os.environ['WANDB_API_KEY']=userdata.get('WANDB_API_KEY')\n",
        "\n",
        "if not userdata.get('WANDB_API_KEY'):\n",
        "    print(\"Error: WANDB_API_KEY is missing or empty. It can be retrieved from https://wandb.ai/authorize. Exiting...\")\n",
        "    sys.exit(1)  # Exit the notebook with an error code\n",
        "\n",
        "# Auth user\n",
        "auth.authenticate_user()\n",
        "gcloud_token = !gcloud auth print-access-token\n",
        "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "\n",
        "USER=gcloud_tokeninfo['email'].split(\"@\")[0]"
      ],
      "metadata": {
        "id": "HRuwUZRbLBLc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repository\n",
        "# Check if the repository already exists\n",
        "%cd /content\n",
        "BRANCH=\"main\"\n",
        "!if [ ! -d \"fp-dataset-artifacts\" ]; then \\\n",
        "    echo \"Repository not found. Cloning...\"; \\\n",
        "    git clone -b $BRANCH https://github.com/pkey/fp-dataset-artifacts.git; \\\n",
        "else \\\n",
        "    echo \"Repository already exists. Pulling latest changes...\"; \\\n",
        "    cd fp-dataset-artifacts && git checkout $BRANCH && git pull origin $BRANCH; \\\n",
        "fi\n",
        "\n",
        "%cd fp-dataset-artifacts"
      ],
      "metadata": {
        "id": "vzahVV1Q-8-7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise colab environment\n",
        "!make initialise/colab"
      ],
      "metadata": {
        "id": "Zbbd8qde8Xr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training or Evaluation"
      ],
      "metadata": {
        "id": "lSkF1PJQFBpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train. You can use whatever command, either from Makefile or directly. MAKE SURE TO RUN THE PREP STEPS (or run all), Command + F9.\n",
        "\n",
        "# Choose if you want to do both or only one\n",
        "TRAINING = True\n",
        "EVALUATION = True\n",
        "\n",
        "current_date_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "EXPERIMENT_NAME = f\"{USER}-{current_date_time}\"\n",
        "os.environ['WANDB_NAME'] = EXPERIMENT_NAME\n",
        "print(\"Experiment name: \", EXPERIMENT_NAME)\n",
        "\n",
        "os.environ['WANDB_PROJECT'] = \"NLP Final Project 2024\"\n",
        "\n",
        "# NOTE: Add here a small note on what changed or what is special about this experiment\n",
        "os.environ['WANDB_NOTES']= input(\"Your experiment notes: \")\n",
        "\n",
        "# NOTE: Depending on GPU, can experiment\n",
        "PER_DEVICE_TRAIN_BATCH_SIZE=60\n",
        "\n",
        "# We are working with squad and hotpot\n",
        "DATASET = \"squad\"\n",
        "\n",
        "# We are using QA mostly so this one should stay unchanged\n",
        "TASK = \"qa\"\n",
        "\n",
        "MODEL_PATH = f\"{TRAIN_PATH}/{EXPERIMENT_NAME}\"\n",
        "print(\"Model will be saved at: \", MODEL_PATH)\n",
        "\n",
        "if (TRAINING):\n",
        "    !python3 run.py --do_train --task $TASK --dataset $DATASET --output_dir \"${MODEL_PATH}\" --per_device_train_batch_size $PER_DEVICE_TRAIN_BATCH_SIZE\n",
        "else:\n",
        "    print(\"Skipping training...\")\n",
        "\n",
        "if (EVALUATION):\n",
        "    !python3 run.py --do_eval --task $TASK --dataset $DATASET --model \"${MODEL_PATH}\" --output_dir \"${TRAIN_PATH}/eval_${EXPERIMENT_NAME}\"\n",
        "else:\n",
        "    print(\"Skipping evaluation...\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xAMDXvNo8wdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "zOx1pDqlxn2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: this might need to change. We might want a different model or a different name. And we might not want to train\n",
        "\n",
        "\n",
        "!python3 run.py --do_eval --task $TASK --dataset $DATASET --model \"${MODEL_PATH}\" --output_dir \"${TRAIN_PATH}/eval_${EXPERIMENT_NAME}\""
      ],
      "metadata": {
        "id": "2eRLiTEWv-aN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}