{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš¨ Any changes here will be overwritten by git. Keep in mind when making any editions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82V6cZ2M-f0-"
   },
   "source": [
    "# Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRuwUZRbLBLc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from google.colab import drive\n",
    "from google.colab import userdata\n",
    "\n",
    "#TODO: add rsync from here to GitHub pre-commit hook (it's tempting to edit the file here)\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "try:\n",
    "  MODEL_TRAINING_PATH = userdata.get('MODEL_TRAINING_PATH')\n",
    "except userdata.SecretNotFoundError as e:\n",
    "    print(\n",
    "        \"Error: Path to shared model training not found, please point to it. \\n\"\n",
    "        \"Should be something like: /content/drive/My Drive/ut/nlp_final/model_training\"\n",
    "        \"The path should be a shortcut to this folder https://drive.google.com/drive/folders/1kyZuHKEu0cc-VFNJvxo0CK0poBFeesXz ,\\n\"\n",
    "        \" stored in your local GDrive. \\n\"\n",
    "        \"Exiting...\"\n",
    "    )\n",
    "    #TODO: not really nice output not sure how to make better\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "os.environ['MODEL_TRAINING_PATH'] = MODEL_TRAINING_PATH\n",
    "\n",
    "# Import secrets\n",
    "os.environ['WANDB_API_KEY']=userdata.get('WANDB_API_KEY')\n",
    "\n",
    "if not userdata.get('WANDB_API_KEY'):\n",
    "    print(\"Error: WANDB_API_KEY is missing or empty. It can be retrieved from https://wandb.ai/authorize. Exiting...\")\n",
    "    exit  # Exit the notebook with an error code\n",
    "\n",
    "# Auth user\n",
    "try:\n",
    "  USER = userdata.get('USER')\n",
    "except userdata.SecretNotFoundError as e:\n",
    "    print(\n",
    "        \"Error. Add your name to the secrets (quicker than google auth each time).\"\n",
    "    )\n",
    "    #TODO: not really nice output not sure how to make better\n",
    "    sys.exit(0)\n",
    "\n",
    "print(\"User: \", USER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "vzahVV1Q-8-7"
   },
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "# Check if the repository already exists\n",
    "%cd /content\n",
    "BRANCH=\"main\"\n",
    "!if [ ! -d \"fp-dataset-artifacts\" ]; then \\\n",
    "    echo \"Repository not found. Cloning...\"; \\\n",
    "    git clone -b $BRANCH https://github.com/pkey/fp-dataset-artifacts.git; \\\n",
    "else \\\n",
    "    echo \"Repository already exists. Pulling latest changes...\"; \\\n",
    "    cd fp-dataset-artifacts && git checkout $BRANCH && git pull origin $BRANCH; \\\n",
    "fi\n",
    "\n",
    "%cd fp-dataset-artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zbbd8qde8Xr6"
   },
   "outputs": [],
   "source": [
    "# Initialise colab environment\n",
    "!make initialise/colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSkF1PJQFBpV"
   },
   "source": [
    "# Training or Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAMDXvNo8wdR"
   },
   "outputs": [],
   "source": [
    "# Train. You can use whatever command, either from Makefile or directly. MAKE SURE TO RUN THE PREP STEPS (or run all), Command + F9.\n",
    "\n",
    "# Choose if you want to do both or only one\n",
    "TRAINING = False\n",
    "EVALUATION = False\n",
    "EVALUATION_BASE_SQUAD = False\n",
    "\n",
    "if not TRAINING and not EVALUATION:\n",
    "    print(\"Please choose one of training or evaluation to proceed\")\n",
    "    sys.exit(0)\n",
    "\n",
    "current_date_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "EXPERIMENT_NAME = f\"{USER}-{current_date_time}\"\n",
    "os.environ['WANDB_NAME'] = EXPERIMENT_NAME\n",
    "print(\"Experiment name: \", EXPERIMENT_NAME)\n",
    "\n",
    "os.environ['WANDB_PROJECT'] = \"NLP Final Project 2024\"\n",
    "\n",
    "# NOTE: Add here a small note on what changed or what is special about this experiment\n",
    "os.environ['WANDB_NOTES']= input(\"Your experiment notes: \")\n",
    "\n",
    "# NOTE: Depending on GPU, can experiment\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE=60\n",
    "\n",
    "# We are working with squad / squad_v2\n",
    "DATASET = \"squad\"\n",
    "\n",
    "# We are using QA mostly so this one should stay unchanged\n",
    "TASK = \"qa\"\n",
    "\n",
    "MODEL_PATH = f\"{MODEL_TRAINING_PATH}/{EXPERIMENT_NAME}\"\n",
    "\n",
    "\n",
    "if (TRAINING):\n",
    "    print(\"Model will be saved at: \", MODEL_PATH)\n",
    "    !python3 run.py --do_train --task $TASK --dataset $DATASET --output_dir \"{MODEL_PATH}\" --per_device_train_batch_size $PER_DEVICE_TRAIN_BATCH_SIZE\n",
    "else:\n",
    "    print(\"Skipping training...\")\n",
    "\n",
    "#TODO: we might not always want to eval the same model. Arrange params in a nicer way here.\n",
    "if EVALUATION:\n",
    "    if EVALUATION_BASE_SQUAD:\n",
    "        MODEL_PATH = f\"{MODEL_TRAINING_PATH}/trained_model_electra_{DATASET}\"\n",
    "    \n",
    "    !python3 run.py --do_eval --task $TASK --dataset $DATASET --model \"{MODEL_PATH}\" --output_dir \"{MODEL_TRAINING_PATH}/eval_{EXPERIMENT_NAME}\"\n",
    "else:\n",
    "    print(\"Skipping evaluation...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis (can be run locally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump incorrect predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Locally, run make initialise/local to make sure .env is available\n",
    "MODEL_TRAINING_PATH = os.getenv(\"MODEL_TRAINING_PATH\")\n",
    "\n",
    "# Analysis of output predictions (can bu run locally as well)\n",
    "# NOTE: Change the path to your evaluation:\n",
    "EVALUATION_PATH=f\"{MODEL_TRAINING_PATH}/eval_squad\"\n",
    "\n",
    "df = pd.read_json(f\"{EVALUATION_PATH}/eval_predictions.jsonl\", lines=True)\n",
    "\n",
    "# Filter rows where there isn't an exact match in the answers_text list\n",
    "df_filtered = df[df.apply(lambda row: row[\"predicted_answer\"] not in row[\"answers\"][\"text\"], axis=1)]\n",
    "\n",
    "# You can view the csv in Google Sheets in google drive (will create a new sheet)\n",
    "df_filtered.to_csv(f\"{EVALUATION_PATH}/filtered_predictions.csv\", index=False, header=True, sep=',', encoding='utf-8')\n",
    "print(f\"Incorrect answers saved to: {EVALUATION_PATH}/filtered_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "cell_execution_strategy": "setup",
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ut_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
