{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82V6cZ2M-f0-"
   },
   "source": [
    "# Prepare Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRuwUZRbLBLc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from google.colab import drive\n",
    "from google.colab import userdata\n",
    "from google.colab import auth\n",
    "\n",
    "#TODO: add rsync from here to GitHub pre-commit hook (it's tempting to edit the file here)\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "try:\n",
    "  MODEL_TRAINING_PATH = userdata.get('MODEL_TRAINING_PATH')\n",
    "except userdata.SecretNotFoundError as e:\n",
    "    print(\n",
    "        \"Error: Path to shared model training not found, please point to it. \\n\"\n",
    "        \"Should be something like: /content/drive/My Drive/ut/nlp_final/model_training\"\n",
    "        \"The path should be a shortcut to this folder https://drive.google.com/drive/folders/1kyZuHKEu0cc-VFNJvxo0CK0poBFeesXz ,\\n\"\n",
    "        \" stored in your local GDrive. \\n\"\n",
    "        \"Exiting...\"\n",
    "    )\n",
    "    #TODO: not really nice output not sure how to make better\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "os.environ['MODEL_TRAINING_PATH'] = MODEL_TRAINING_PATH\n",
    "\n",
    "# Import secrets\n",
    "os.environ['WANDB_API_KEY']=userdata.get('WANDB_API_KEY')\n",
    "\n",
    "if not userdata.get('WANDB_API_KEY'):\n",
    "    print(\"Error: WANDB_API_KEY is missing or empty. It can be retrieved from https://wandb.ai/authorize. Exiting...\")\n",
    "    exit  # Exit the notebook with an error code\n",
    "\n",
    "# Auth user\n",
    "auth.authenticate_user()\n",
    "gcloud_token = !gcloud auth print-access-token\n",
    "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
    "\n",
    "USER=gcloud_tokeninfo['email'].split(\"@\")[0]\n",
    "print(\"User: \", USER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "vzahVV1Q-8-7"
   },
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "# Check if the repository already exists\n",
    "%cd /content\n",
    "BRANCH=\"main\"\n",
    "!if [ ! -d \"fp-dataset-artifacts\" ]; then \\\n",
    "    echo \"Repository not found. Cloning...\"; \\\n",
    "    git clone -b $BRANCH https://github.com/pkey/fp-dataset-artifacts.git; \\\n",
    "else \\\n",
    "    echo \"Repository already exists. Pulling latest changes...\"; \\\n",
    "    cd fp-dataset-artifacts && git checkout $BRANCH && git pull origin $BRANCH; \\\n",
    "fi\n",
    "\n",
    "%cd fp-dataset-artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zbbd8qde8Xr6"
   },
   "outputs": [],
   "source": [
    "# Initialise colab environment\n",
    "!make initialise/colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSkF1PJQFBpV"
   },
   "source": [
    "# Training or Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAMDXvNo8wdR"
   },
   "outputs": [],
   "source": [
    "# Train. You can use whatever command, either from Makefile or directly. MAKE SURE TO RUN THE PREP STEPS (or run all), Command + F9.\n",
    "\n",
    "# Choose if you want to do both or only one\n",
    "TRAINING = True\n",
    "EVALUATION = True\n",
    "\n",
    "current_date_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "EXPERIMENT_NAME = f\"{USER}-{current_date_time}\"\n",
    "os.environ['WANDB_NAME'] = EXPERIMENT_NAME\n",
    "print(\"Experiment name: \", EXPERIMENT_NAME)\n",
    "\n",
    "os.environ['WANDB_PROJECT'] = \"NLP Final Project 2024\"\n",
    "\n",
    "# NOTE: Add here a small note on what changed or what is special about this experiment\n",
    "os.environ['WANDB_NOTES']= input(\"Your experiment notes: \")\n",
    "\n",
    "# NOTE: Depending on GPU, can experiment\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE=60\n",
    "\n",
    "# We are working with squad and hotpot\n",
    "DATASET = \"squad\"\n",
    "\n",
    "# We are using QA mostly so this one should stay unchanged\n",
    "TASK = \"qa\"\n",
    "\n",
    "MODEL_PATH = f\"{MODEL_TRAINING_PATH}/{EXPERIMENT_NAME}\"\n",
    "print(\"Model will be saved at: \", MODEL_PATH)\n",
    "\n",
    "if (TRAINING):\n",
    "    !python3 run.py --do_train --task $TASK --dataset $DATASET --output_dir \"{MODEL_PATH}\" --per_device_train_batch_size $PER_DEVICE_TRAIN_BATCH_SIZE\n",
    "else:\n",
    "    print(\"Skipping training...\")\n",
    "\n",
    "#TODO: we might not always want to eval the same model. Arrange params in a nicer way here. test\n",
    "if (EVALUATION):\n",
    "    !python3 run.py --do_eval --task $TASK --dataset $DATASET --model \"{MODEL_PATH}\" --output_dir \"${MODEL_TRAINING_PATH}/eval_${EXPERIMENT_NAME}\"\n",
    "else:\n",
    "    print(\"Skipping evaluation...\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "cell_execution_strategy": "setup",
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
